{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo livro - Approaching (almost) any Machine Learning Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando vamos desenvolver algoritmos de machine learning, podemos utilizar diversas métricas de avaliação. Algumas vezes, criamos métricas novas para atender uma necessidade de compreensão para o negócio. Nesse notebook, vamos avaliar as métricas mais comums que podem ser usadas nos mais variados tipos de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante notar que trataremos apensa de métricas de avaliaçao para algotirmos supervisionados devido a grande abundancia desse tipo de problema na indústria e o fato das métricas de avaliação de problemas não supervisionados são um pouco subjetivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As métricas mais usadas para problemas de Classificação são:\n",
    "* Accuracy \n",
    "* Precision (P)\n",
    "* Recall (R)\n",
    "* F1 score (F1)\n",
    "* Area under the ROC (Roceiver Operating Characteristic) curve ou AUC \n",
    "* Log Loss\n",
    "* Precision at k (P@k)\n",
    "* Average Precision at k (AP@k)\n",
    "* Mean Average Precision at k (MAP@k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As métricas mais usadas para problemas de Regressão são:\n",
    "* Mean Absolute Error (MAE) \n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "* Root Mean Squared Logarithmic error (RMSLE)\n",
    "* Mean Percentage Error (MPE) \n",
    "* Mean Absolute Percentage Error (MAPE)\n",
    "* R²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saber trabalhar com as métricas mensionadas acima não a única coisa que nós devemos saber. Além disso, devemos saber quando usar quando usar cada uma delas, e isso depende do tipo de dados que temos e do target em questão. \n",
    "\n",
    "*Nota: O autor mensiona que se \"preocupa\" mais com os targets e menos com os tipos de data para saber qual métrica escolher*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender um pouco sobre as métricas, vamos começar com um problema simples de classificação. Vamos supoer que temos um problema de classificação binária ( apenas dois targets) e tal problema consiste em classificar imagens de raio-X toráxica. Temos imagens de raio-x sem problema algum e outras com pneumatorax. Nossa tarefa é montar um algoritmo de classificação que dada uma imagem de raio-x, consiga detectar a presença de pneumatorax. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'imagens/pneumotorax.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos assumir que temos dados balanceados, ou seja, o número de casos com pneumatorax é igual ao número de casos sem o problema. Se tivermos 100 casos positivos, então teremos 100 casos negativos também.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira coisa a se fazer é separar os dados em dois sets iguais de 100 imagens ( set de treino e de validação). Em cada um dos sets, teremos 50 casos positivos e 50 casos negativos para garantir o balanceamento das classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Quando temos o mesmo número de classes positivas e negativas num problema de classificação binário,nós usamos as seguintes métricas:\n",
    "> * Accuracy\n",
    "> * Precision\n",
    "> * Recall\n",
    "> * F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** ou acurácia é a métrica mais simples usada em machine learning. É definido como o quão preciso o modelo é em geral. Para o problema anterior, se a gente constroi um modelo que classifica **90 imagens corretamente**, nossa **accuracy (ou acurácia) é de 90% ou 0.9**. Se somente 83 imagens são classificadas corretamente, a accuracy é de 83% ou 0.83."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos calcular accuracy com Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.625\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    # Inicializa o contador para previsões corretas\n",
    "    correct = 0\n",
    "    \n",
    "    # loop sobre todos elementos de y_true e y_pred \n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            correct += 1\n",
    "    \n",
    "    # retorna o avalor da accuracy que é a quantidade de previsões corretas sobre o total\n",
    "    return (correct/ len(y_true))\n",
    "\n",
    "\n",
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy = accuracy(y_true, y_pred)\n",
    "print(f\"Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Povemos também realizar o cálculo da acurácia com o scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy_sklearn = metrics.accuracy_score(y_true,y_pred)\n",
    "\n",
    "print(f\"Accuracy : {accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
