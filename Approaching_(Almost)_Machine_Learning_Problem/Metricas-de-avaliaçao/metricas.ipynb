{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo livro - Approaching (almost) any Machine Learning Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando vamos desenvolver algoritmos de machine learning, podemos utilizar diversas métricas de avaliação. Algumas vezes, criamos métricas novas para atender uma necessidade de compreensão para o negócio. Nesse notebook, vamos avaliar as métricas mais comums que podem ser usadas nos mais variados tipos de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante notar que trataremos apensa de métricas de avaliaçao para algotirmos supervisionados devido a grande abundancia desse tipo de problema na indústria e o fato das métricas de avaliação de problemas não supervisionados são um pouco subjetivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As métricas mais usadas para problemas de Classificação são:\n",
    "* Accuracy \n",
    "* Precision (P)\n",
    "* Recall (R)\n",
    "* F1 score (F1)\n",
    "* Area under the ROC (Roceiver Operating Characteristic) curve ou AUC \n",
    "* Log Loss\n",
    "* Precision at k (P@k)\n",
    "* Average Precision at k (AP@k)\n",
    "* Mean Average Precision at k (MAP@k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As métricas mais usadas para problemas de Regressão são:\n",
    "* Mean Absolute Error (MAE) \n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "* Root Mean Squared Logarithmic error (RMSLE)\n",
    "* Mean Percentage Error (MPE) \n",
    "* Mean Absolute Percentage Error (MAPE)\n",
    "* R²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saber trabalhar com as métricas mensionadas acima não a única coisa que nós devemos saber. Além disso, devemos saber quando usar quando usar cada uma delas, e isso depende do tipo de dados que temos e do target em questão. \n",
    "\n",
    "*Nota: O autor mensiona que se \"preocupa\" mais com os targets e menos com os tipos de data para saber qual métrica escolher*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender um pouco sobre as métricas, vamos começar com um problema simples de classificação. Vamos supoer que temos um problema de classificação binária ( apenas dois targets) e tal problema consiste em classificar imagens de raio-X toráxica. Temos imagens de raio-x sem problema algum e outras com pneumatorax. Nossa tarefa é montar um algoritmo de classificação que dada uma imagem de raio-x, consiga detectar a presença de pneumatorax. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'imagens/pneumotorax.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos assumir que temos dados balanceados, ou seja, o número de casos com pneumatorax é igual ao número de casos sem o problema. Se tivermos 100 casos positivos, então teremos 100 casos negativos também.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira coisa a se fazer é separar os dados em dois sets iguais de 100 imagens ( set de treino e de validação). Em cada um dos sets, teremos 50 casos positivos e 50 casos negativos para garantir o balanceamento das classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Quando temos o mesmo número de classes positivas e negativas num problema de classificação binário,nós usamos as seguintes métricas:\n",
    "> * Accuracy\n",
    "> * Precision\n",
    "> * Recall\n",
    "> * F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** ou acurácia é a métrica mais simples usada em machine learning. É definido como o quão preciso o modelo é em geral. Para o problema anterior, se a gente constroi um modelo que classifica **90 imagens corretamente**, nossa **accuracy (ou acurácia) é de 90% ou 0.9**. Se somente 83 imagens são classificadas corretamente, a accuracy é de 83% ou 0.83."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos calcular accuracy com Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.625\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    # Inicializa o contador para previsões corretas\n",
    "    correct = 0\n",
    "    \n",
    "    # loop sobre todos elementos de y_true e y_pred \n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            correct += 1\n",
    "    \n",
    "    # retorna o avalor da accuracy que é a quantidade de previsões corretas sobre o total\n",
    "    return (correct/ len(y_true))\n",
    "\n",
    "\n",
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy = accuracy(y_true, y_pred)\n",
    "print(f\"Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Povemos também realizar o cálculo da acurácia com o scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy_sklearn = metrics.accuracy_score(y_true,y_pred)\n",
    "\n",
    "print(f\"Accuracy : {accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Desbalanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos considerar que temos um dataset desbalanceado com 180 imagens de pacientes que não possuem pneumatórax e apenas 20 que possuem.Mesmo para esse caso, nós iremos criar os datasets de treinamento e validação com as mesmas proporções de targets positivos e negativos. Em cada set, teremos 90 imagems sem pneumatórax e 10 imagens com pneumatórax. *Para a situação em questão, se você disser que todas as imagens do set de validação são de pacientes que não possuem pneumatórax, a acurácia seria de 90%!*\n",
    "\n",
    "É notório que temos classes desbalanceadas com uma delas significativamente maior que a outra.**Nesse caso, não é recomendado usar a acurácia como métrica de avaliação pois ela não é representativa para os dados em questão**. Mesmo que tenhamos uma acurácia grande, o modelo provavelmente terá uma performance pobre quando for aplicado para dados de produção e você terá sérios problemas para explicar para o seu gerente o motivo.\n",
    "\n",
    "**Em casos como esse, é melhor olhar para outras métricas como por exemplo a precision.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de falar em precision, vamos entender outros termos importantes. Vamos assumir que imagem com pneumatórax são da classe positiva (1) e imagens sem são da classe negativa (0).\n",
    "\n",
    "**True Positive (TP) ou Verdadeiro Positivo (VP)**: Dada uma imagem, se o modelo prever que tal imagem possui pneumatórax e o valor de target da imagem mostra que o paciente realmente possui pneumatórax, é considerado true positive ou verdadeiro positivo.\n",
    "\n",
    "**True Negative (TN) ou Verdadeiro Negativo (VN)**: Dada uma imagem, se o modelo prever que essa imagem não possui pneumatórax e a imagem é de um paciente que realmente não possui pneumatórax, é considerado True Negative.\n",
    "\n",
    "Resumindo:\n",
    "* *Se o modelo prever corretamente classe positiva, é* **True Positive**\n",
    "* *Se o modelo prever corretamente classe negativa, é* **True Negative**\n",
    "\n",
    "**False Positive (FP) ou Falso Positivo**: Dada uma imagem, se o modelo prever pneumatórax porém a imagem é de um paciente sem pneumatórax, é um False Positive.\n",
    "\n",
    "**False Negative (FN) ou Falso Negativo**: Dada uma imagem, se o modelo prever que a imagem não é de paciente com pneumatórax, porém o paciente possui pneumatórax, é um False Negative.\n",
    "\n",
    "Resumindo:\n",
    "* *Se o modelo prever incorretamente classe positiva, é* **False Positive**\n",
    "* *Se o modelo prever incorretamente classe negativa, é* **False Negative**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos olhar a implementação em python dos conceitos apresentados acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    true_pos = 0\n",
    "    for yt,yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            true_pos += 1\n",
    "    \n",
    "    return true_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_negative(y_true,y_pred):\n",
    "    true_neg = 0\n",
    "    for yt,yp in zip(y_true,y_pred):\n",
    "        if yt == 0 and yp ==0:\n",
    "            true_neg += 1\n",
    "            \n",
    "    return true_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positive(y_true, y_pred):\n",
    "    false_pos = 0\n",
    "    for yt,yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp ==1:\n",
    "            false_pos += 1\n",
    "            \n",
    "    return false_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_negative(y_true, y_pred):\n",
    "    false_neg = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            false_neg += 1\n",
    "            \n",
    "    return false_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota: As funções aplicadas acima funcionam apenas para classificação binária.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_Y = [0,1,1,1,0,0,0,1]\n",
    "y_Pred = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_negative(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se formos definir **Accuracy** com os termos apresentados acima, nós teríamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Score:$$ Accuracy_Score = (TP + TN) / (TP + TN+FP + FN) $$\n",
    "\\frac{ (TP + TN)}{(TP + TN+FP + FN)}\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Accuracy Score = \\frac{ (TP + TN)}{(TP + TN+FP + FN)}\\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
