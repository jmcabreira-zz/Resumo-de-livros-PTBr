{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo livro - Approaching (almost) any Machine Learning Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando vamos desenvolver algoritmos de machine learning, podemos utilizar diversas métricas de avaliação. Algumas vezes, criamos métricas novas para atender uma necessidade de compreensão para o negócio. Nesse notebook, vamos avaliar as métricas mais comums que podem ser usadas nos mais variados tipos de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante notar que trataremos apensa de métricas de avaliaçao para algotirmos supervisionados devido a grande abundancia desse tipo de problema na indústria e o fato das métricas de avaliação de problemas não supervisionados são um pouco subjetivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As métricas mais usadas para problemas de Classificação são:\n",
    "* Accuracy \n",
    "* Precision (P)\n",
    "* Recall (R)\n",
    "* F1 score (F1)\n",
    "* Area under the ROC (Roceiver Operating Characteristic) curve ou AUC \n",
    "* Log Loss\n",
    "* Precision at k (P@k)\n",
    "* Average Precision at k (AP@k)\n",
    "* Mean Average Precision at k (MAP@k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As métricas mais usadas para problemas de Regressão são:\n",
    "* Mean Absolute Error (MAE) \n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "* Root Mean Squared Logarithmic error (RMSLE)\n",
    "* Mean Percentage Error (MPE) \n",
    "* Mean Absolute Percentage Error (MAPE)\n",
    "* R²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saber trabalhar com as métricas mensionadas acima não a única coisa que nós devemos saber. Além disso, devemos saber quando usar quando usar cada uma delas, e isso depende do tipo de dados que temos e do target em questão. \n",
    "\n",
    "*Nota: O autor mensiona que se \"preocupa\" mais com os targets e menos com os tipos de data para saber qual métrica escolher*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender um pouco sobre as métricas, vamos começar com um problema simples de classificação. Vamos supoer que temos um problema de classificação binária ( apenas dois targets) e tal problema consiste em classificar imagens de raio-X toráxica. Temos imagens de raio-x sem problema algum e outras com pneumatorax. Nossa tarefa é montar um algoritmo de classificação que dada uma imagem de raio-x, consiga detectar a presença de pneumatorax. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'imagens/pneumotorax.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos assumir que temos dados balanceados, ou seja, o número de casos com pneumatorax é igual ao número de casos sem o problema. Se tivermos 100 casos positivos, então teremos 100 casos negativos também.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira coisa a se fazer é separar os dados em dois sets iguais de 100 imagens ( set de treino e de validação). Em cada um dos sets, teremos 50 casos positivos e 50 casos negativos para garantir o balanceamento das classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Quando temos o mesmo número de classes positivas e negativas num problema de classificação binário,nós usamos as seguintes métricas:\n",
    "> * Accuracy\n",
    "> * Precision\n",
    "> * Recall\n",
    "> * F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy ou Acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** ou acurácia é a métrica mais simples usada em machine learning. É definido como o quão preciso o modelo é em geral. Para o problema anterior, se a gente constroi um modelo que classifica **90 imagens corretamente**, nossa **accuracy (ou acurácia) é de 90% ou 0.9**. Se somente 83 imagens são classificadas corretamente, a accuracy é de 83% ou 0.83."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos calcular accuracy com Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    # Inicializa o contador para previsões corretas\n",
    "    correct = 0\n",
    "    \n",
    "    # loop sobre todos elementos de y_true e y_pred \n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            correct += 1\n",
    "    \n",
    "    # retorna o avalor da accuracy que é a quantidade de previsões corretas sobre o total\n",
    "    return (correct/ len(y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.625\n"
     ]
    }
   ],
   "source": [
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy_ = accuracy(y_true, y_pred)\n",
    "print(f\"Accuracy : {accuracy_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Povemos também realizar o cálculo da acurácia com o scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy_sklearn = metrics.accuracy_score(y_true,y_pred)\n",
    "\n",
    "print(f\"Accuracy : {accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Desbalanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos considerar que temos um dataset desbalanceado com 180 imagens de pacientes que não possuem pneumatórax e apenas 20 que possuem.Mesmo para esse caso, nós iremos criar os datasets de treinamento e validação com as mesmas proporções de targets positivos e negativos. Em cada set, teremos 90 imagems sem pneumatórax e 10 imagens com pneumatórax. *Para a situação em questão, se você disser que todas as imagens do set de validação são de pacientes que não possuem pneumatórax, a acurácia seria de 90%!*\n",
    "\n",
    "É notório que temos classes desbalanceadas com uma delas significativamente maior que a outra.**Nesse caso, não é recomendado usar a acurácia como métrica de avaliação pois ela não é representativa para os dados em questão**. Mesmo que tenhamos uma acurácia grande, o modelo provavelmente terá uma performance pobre quando for aplicado para dados de produção e você terá sérios problemas para explicar para o seu gerente o motivo.\n",
    "\n",
    "**Em casos como esse, é melhor olhar para outras métricas como por exemplo a precision.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de falar em precision, vamos entender outros termos importantes. Vamos assumir que imagem com pneumatórax são da classe positiva (1) e imagens sem são da classe negativa (0).\n",
    "\n",
    "**True Positive (TP) ou Verdadeiro Positivo (VP)**: Dada uma imagem, se o modelo prever que tal imagem possui pneumatórax e o valor de target da imagem mostra que o paciente realmente possui pneumatórax, é considerado true positive ou verdadeiro positivo.\n",
    "\n",
    "**True Negative (TN) ou Verdadeiro Negativo (VN)**: Dada uma imagem, se o modelo prever que essa imagem não possui pneumatórax e a imagem é de um paciente que realmente não possui pneumatórax, é considerado True Negative.\n",
    "\n",
    "Resumindo:\n",
    "* *Se o modelo prever corretamente classe positiva, é* **True Positive**\n",
    "* *Se o modelo prever corretamente classe negativa, é* **True Negative**\n",
    "\n",
    "**False Positive (FP) ou Falso Positivo**: Dada uma imagem, se o modelo prever pneumatórax porém a imagem é de um paciente sem pneumatórax, é um False Positive.\n",
    "\n",
    "**False Negative (FN) ou Falso Negativo**: Dada uma imagem, se o modelo prever que a imagem não é de paciente com pneumatórax, porém o paciente possui pneumatórax, é um False Negative.\n",
    "\n",
    "Resumindo:\n",
    "* *Se o modelo prever incorretamente classe positiva, é* **False Positive**\n",
    "* *Se o modelo prever incorretamente classe negativa, é* **False Negative**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos olhar a implementação em python dos conceitos apresentados acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    true_pos = 0\n",
    "    for yt,yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            true_pos += 1\n",
    "    \n",
    "    return true_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_negative(y_true,y_pred):\n",
    "    true_neg = 0\n",
    "    for yt,yp in zip(y_true,y_pred):\n",
    "        if yt == 0 and yp ==0:\n",
    "            true_neg += 1\n",
    "            \n",
    "    return true_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positive(y_true, y_pred):\n",
    "    false_pos = 0\n",
    "    for yt,yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp ==1:\n",
    "            false_pos += 1\n",
    "            \n",
    "    return false_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_negative(y_true, y_pred):\n",
    "    false_neg = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            false_neg += 1\n",
    "            \n",
    "    return false_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota: As funções aplicadas acima funcionam apenas para classificação binária.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_Y = [0,1,1,1,0,0,0,1]\n",
    "y_Pred = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_negative(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se formos definir **Accuracy** com os termos apresentados acima, nós teríamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Accuracy Score = \\frac{ (TP + TN)}{(TP + TN+FP + FN)}\\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que conhecemos todos esses conceito, podemos calcular a acurácia usingo TP, TM, FP, e FN em python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_v2(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    \n",
    "    accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    return accuracy    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agora vamos comparar os resultados com a versao do *scikit-learn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Versão 1:  0.625\n",
      "Accuracy Versão 2:  0.625\n",
      "Accuracy Versão sklearn:  0.625\n"
     ]
    }
   ],
   "source": [
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy_1 = accuracy(y_true, y_pred)\n",
    "print('Accuracy Versão 1: ', accuracy_1)\n",
    "\n",
    "accuracy_2 = accuracy_v2(y_true, y_pred)\n",
    "print('Accuracy Versão 2: ', accuracy_2)\n",
    "\n",
    "from sklearn import metrics\n",
    "accuracy_scikit_learn = metrics.accuracy_score(y_true, y_pred)\n",
    "print('Accuracy Versão sklearn: ', accuracy_scikit_learn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ótimos, agora vimos três maneiras de calcular acurácia e estão todas dando o mesmo resultado.\n",
    "\n",
    "Agora vamos conhecer melhor e avaliar outras métricas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira será **Precision**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Precision = \\frac{ TP }{(TP +FP)}\\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos supor que construímos um novo modelo em dados que também são desbalanceados. Diante dessas condições, nosso modelo identificou corretamente 80 casos de não pneumatórax num total de 90 e 8 casos de pneumatórax num total de 10. Consequentemente, o modelo identificou corretamente 88 imagens num total de 100. A **acurácia** nesse caso é de 0,88 ou 88%.\n",
    "\n",
    "Porém do total de 100 imagens, 10 images sem pneumatórax são classificadas incorretamente como casos com pneumatórax. Além disso, 2 casos de pneumatórax foram  classificados incorretamente como sem pneumatórax.\n",
    "\n",
    "Diante disso, temos:\n",
    ">  - TP: 8\n",
    ">  - TN: 80\n",
    ">  - FP: 10\n",
    ">  - FN: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa **Precision** será:\n",
    "    \n",
    "\\begin{equation*}\n",
    "Precision = \\frac{ 8 }{(8 +10)}= 0,444\\\\ \n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Isso significa que nosso modelo está correto 44% das vezes quando tenta identificar casos de pneumatórax.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos aplicar precision em python:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "precision_ = precision(y_true, y_pred)\n",
    "print('precision:', precision_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos analisar **Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** é definido como:\n",
    "    \n",
    "\\begin{equation*}\n",
    "Recall = \\frac{ TP }{(TP + FN)}\\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa **Recall** será:\n",
    "    \n",
    "\\begin{equation*}\n",
    "Precision = \\frac{ 8 }{(8 + 2)}= 0,80\\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Isso significa que nosso modelo identificou 80% dos casos positivos de pneumatórax corretamente**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vamos aplicar o cálculo em python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    \n",
    "    recall = tp/ (tp + fn)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "recall_ = recall(y_true, y_pred)\n",
    "print('recall:', recall_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um bom modelo de machine learning, os valores de precision e recall precisam ser altos. Podemos observar isso no caso anterior, o valor de recall é 'um pouco' alto. Em contrapartida o valor de precision é muito baixo!\n",
    "\n",
    "Nosso modelo reproduz bastante falso positivos porém menos faso negativos. Poucos casos de falso negativos é bom nesse tipo de problema pois não queremos dizer que um paciente não possui pneumatórax quando na verdade ele possui. Isso pode proporcionar sérios problemas ! Porém ainda temos bastante falso positivos e isso também pode ser um problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grande parte dos modelos prevê probabilidade. Nessas predições nós geralmente escolhemos um threshold de 0,5. Esse limite (threshold) nao é sempre ideal e dependendo do valor escolhido para esse limite, os valores de precision e recall podem mudar drasticamente. Se para cada threshold que a gente escolher, calcularmos os valores de precision e recall, nos criamos uma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de Precision e Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos assumir que temos duas listas:\n",
    "* y_true: os valores de targets\n",
    "* y_pred: Valores de probabilidade da amostra em questão ser da classe 1\n",
    "\n",
    "Agora vamos olhar as probabilidades de predições ao invés do valor que foi predito ( o que é calculado na grande maioria das vezes considerando um limite de 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0,0,0,1,0,0,0,0,0,0,\n",
    "          1,0,0,0,0,0,0,0,1,0]\n",
    "\n",
    "\n",
    "y_pred = [0.263 , 0.111, 0.032, \n",
    "          0.049 , 0.019, 0.175,\n",
    "          0.159 , 0.038, 0.116,\n",
    "          0.079 , 0.085, 0.391,\n",
    "          0.272 , 0.034, 0.046,\n",
    "          0.035 , 0.185, 0.059,\n",
    "          0.612 , 0.033]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(y_true))\n",
    "\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
