{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo livro - Approaching (almost) any Machine Learning Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando vamos desenvolver algoritmos de machine learning, podemos utilizar diversas métricas de avaliação. Algumas vezes, criamos métricas novas para atender uma necessidade de compreensão para o negócio. Nesse notebook, vamos avaliar as métricas mais comums que podem ser usadas nos mais variados tipos de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante notar que trataremos apensa de métricas de avaliaçao para algotirmos supervisionados devido a grande abundancia desse tipo de problema na indústria e o fato das métricas de avaliação de problemas não supervisionados são um pouco subjetivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As métricas mais usadas para problemas de Classificação são:\n",
    "* Accuracy \n",
    "* Precision (P)\n",
    "* Recall (R)\n",
    "* F1 score (F1)\n",
    "* Area under the ROC (Roceiver Operating Characteristic) curve ou AUC \n",
    "* Log Loss\n",
    "* Precision at k (P@k)\n",
    "* Average Precision at k (AP@k)\n",
    "* Mean Average Precision at k (MAP@k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As métricas mais usadas para problemas de Regressão são:\n",
    "* Mean Absolute Error (MAE) \n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "* Root Mean Squared Logarithmic error (RMSLE)\n",
    "* Mean Percentage Error (MPE) \n",
    "* Mean Absolute Percentage Error (MAPE)\n",
    "* R²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saber trabalhar com as métricas mensionadas acima não a única coisa que nós devemos saber. Além disso, devemos saber quando usar quando usar cada uma delas, e isso depende do tipo de dados que temos e do target em questão. \n",
    "\n",
    "*Nota: O autor mensiona que se \"preocupa\" mais com os targets e menos com os tipos de data para saber qual métrica escolher*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender um pouco sobre as métricas, vamos começar com um problema simples de classificação. Vamos supoer que temos um problema de classificação binária ( apenas dois targets) e tal problema consiste em classificar imagens de raio-X toráxica. Temos imagens de raio-x sem problema algum e outras com pneumatorax. Nossa tarefa é montar um algoritmo de classificação que dada uma imagem de raio-x, consiga detectar a presença de pneumatorax. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'imagens/pneumotorax.jpg'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos assumir que temos dados balanceados, ou seja, o número de casos com pneumatorax é igual ao número de casos sem o problema. Se tivermos 100 casos positivos, então teremos 100 casos negativos também.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeira coisa a se fazer é separar os dados em dois sets iguais de 100 imagens ( set de treino e de validação). Em cada um dos sets, teremos 50 casos positivos e 50 casos negativos para garantir o balanceamento das classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Quando temos o mesmo número de classes positivas e negativas num problema de classificação binário,nós usamos as seguintes métricas:\n",
    "> * Accuracy\n",
    "> * Precision\n",
    "> * Recall\n",
    "> * F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy ou Acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** ou acurácia é a métrica mais simples usada em machine learning. É definido como o quão preciso o modelo é em geral. Para o problema anterior, se a gente constroi um modelo que classifica **90 imagens corretamente**, nossa **accuracy (ou acurácia) é de 90% ou 0.9**. Se somente 83 imagens são classificadas corretamente, a accuracy é de 83% ou 0.83."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos calcular accuracy com Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-cb3d36f3af0b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-cb3d36f3af0b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    correct = 0\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "    def accuracy(y_true, y_pred):\n",
    "    # Inicializa o contador para previsões corretas\n",
    "    correct = 0\n",
    "\n",
    "    # loop sobre todos elementos de y_true e y_pred \n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            correct += 1\n",
    "\n",
    "    # retorna o avalor da accuracy que é a quantidade de previsões corretas sobre o total\n",
    "    return (correct/ len(y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aac4dcdb4064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuracy_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy : {accuracy_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy_ = accuracy(y_true, y_pred)\n",
    "print(f\"Accuracy : {accuracy_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Povemos também realizar o cálculo da acurácia com o scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy_sklearn = metrics.accuracy_score(y_true,y_pred)\n",
    "\n",
    "print(f\"Accuracy : {accuracy_sklearn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Desbalanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos considerar que temos um dataset desbalanceado com 180 imagens de pacientes que não possuem pneumatórax e apenas 20 que possuem.Mesmo para esse caso, nós iremos criar os datasets de treinamento e validação com as mesmas proporções de targets positivos e negativos. Em cada set, teremos 90 imagems sem pneumatórax e 10 imagens com pneumatórax. *Para a situação em questão, se você disser que todas as imagens do set de validação são de pacientes que não possuem pneumatórax, a acurácia seria de 90%!*\n",
    "\n",
    "É notório que temos classes desbalanceadas com uma delas significativamente maior que a outra.**Nesse caso, não é recomendado usar a acurácia como métrica de avaliação pois ela não é representativa para os dados em questão**. Mesmo que tenhamos uma acurácia grande, o modelo provavelmente terá uma performance pobre quando for aplicado para dados de produção e você terá sérios problemas para explicar para o seu gerente o motivo.\n",
    "\n",
    "**Em casos como esse, é melhor olhar para outras métricas como por exemplo a precision.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de falar em precision, vamos entender outros termos importantes. Vamos assumir que imagem com pneumatórax são da classe positiva (1) e imagens sem são da classe negativa (0).\n",
    "\n",
    "**True Positive (TP) ou Verdadeiro Positivo (VP)**: Dada uma imagem, se o modelo prever que tal imagem possui pneumatórax e o valor de target da imagem mostra que o paciente realmente possui pneumatórax, é considerado true positive ou verdadeiro positivo.\n",
    "\n",
    "**True Negative (TN) ou Verdadeiro Negativo (VN)**: Dada uma imagem, se o modelo prever que essa imagem não possui pneumatórax e a imagem é de um paciente que realmente não possui pneumatórax, é considerado True Negative.\n",
    "\n",
    "Resumindo:\n",
    "* *Se o modelo prever corretamente classe positiva, é* **True Positive**\n",
    "* *Se o modelo prever corretamente classe negativa, é* **True Negative**\n",
    "\n",
    "**False Positive (FP) ou Falso Positivo**: Dada uma imagem, se o modelo prever pneumatórax porém a imagem é de um paciente sem pneumatórax, é um False Positive.\n",
    "\n",
    "**False Negative (FN) ou Falso Negativo**: Dada uma imagem, se o modelo prever que a imagem não é de paciente com pneumatórax, porém o paciente possui pneumatórax, é um False Negative.\n",
    "\n",
    "Resumindo:\n",
    "* *Se o modelo prever incorretamente classe positiva, é* **False Positive**\n",
    "* *Se o modelo prever incorretamente classe negativa, é* **False Negative**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos olhar a implementação em python dos conceitos apresentados acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    true_pos = 0\n",
    "    for yt,yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            true_pos += 1\n",
    "    \n",
    "    return true_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_negative(y_true,y_pred):\n",
    "    true_neg = 0\n",
    "    for yt,yp in zip(y_true,y_pred):\n",
    "        if yt == 0 and yp ==0:\n",
    "            true_neg += 1\n",
    "            \n",
    "    return true_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positive(y_true, y_pred):\n",
    "    false_pos = 0\n",
    "    for yt,yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp ==1:\n",
    "            false_pos += 1\n",
    "            \n",
    "    return false_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_negative(y_true, y_pred):\n",
    "    false_neg = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            false_neg += 1\n",
    "            \n",
    "    return false_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota: As funções aplicadas acima funcionam apenas para classificação binária.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_Y = [0,1,1,1,0,0,0,1]\n",
    "y_Pred = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0bf511358c66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrue_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_Pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "true_positive(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'false_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d51dbef367c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfalse_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_Pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'false_positive' is not defined"
     ]
    }
   ],
   "source": [
    "false_positive(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative(true_Y, y_Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se formos definir **Accuracy** com os termos apresentados acima, nós teríamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Accuracy Score = \\frac{ (TP + TN)}{(TP + TN+FP + FN)}\\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que conhecemos todos esses conceito, podemos calcular a acurácia usingo TP, TM, FP, e FN em python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_v2(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    \n",
    "    accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    return accuracy    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agora vamos comparar os resultados com a versao do *scikit-learn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-42eeaedfab09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuracy_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy Versão 1: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy_1 = accuracy(y_true, y_pred)\n",
    "print('Accuracy Versão 1: ', accuracy_1)\n",
    "\n",
    "accuracy_2 = accuracy_v2(y_true, y_pred)\n",
    "print('Accuracy Versão 2: ', accuracy_2)\n",
    "\n",
    "from sklearn import metrics\n",
    "accuracy_scikit_learn = metrics.accuracy_score(y_true, y_pred)\n",
    "print('Accuracy Versão sklearn: ', accuracy_scikit_learn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ótimos, agora vimos três maneiras de calcular acurácia e estão todas dando o mesmo resultado.\n",
    "\n",
    "Agora vamos conhecer melhor e avaliar outras métricas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira será **Precision**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Precision = \\frac{ TP }{(TP +FP)}\\\\\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos supor que construímos um novo modelo em dados que também são desbalanceados. Diante dessas condições, nosso modelo identificou corretamente 80 casos de não pneumatórax num total de 90 e 8 casos de pneumatórax num total de 10. Consequentemente, o modelo identificou corretamente 88 imagens num total de 100. A **acurácia** nesse caso é de 0,88 ou 88%.\n",
    "\n",
    "Porém do total de 100 imagens, 10 images sem pneumatórax são classificadas incorretamente como casos com pneumatórax. Além disso, 2 casos de pneumatórax foram  classificados incorretamente como sem pneumatórax.\n",
    "\n",
    "Diante disso, temos:\n",
    ">  - TP: 8\n",
    ">  - TN: 80\n",
    ">  - FP: 10\n",
    ">  - FN: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa **Precision** será:\n",
    "    \n",
    "\\begin{equation*}\n",
    "Precision = \\frac{ 8 }{(8 +10)}= 0,444\\\\ \n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Isso significa que nosso modelo está correto 44% das vezes quando tenta identificar casos de pneumatórax.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos aplicar precision em python:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-04f0234b5454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprecision_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fef6dfd5db63>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "precision_ = precision(y_true, y_pred)\n",
    "print('precision:', precision_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos analisar **Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** é definido como:\n",
    "    \n",
    "\\begin{equation*}\n",
    "Recall = \\frac{ TP }{(TP + FN)}\\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa **Recall** será:\n",
    "    \n",
    "\\begin{equation*}\n",
    "Precision = \\frac{ 8 }{(8 + 2)}= 0,80\\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Isso significa que nosso modelo identificou 80% dos casos positivos de pneumatórax corretamente**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vamos aplicar o cálculo em python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    \n",
    "    recall = tp/ (tp + fn)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-23ef1a3cbaa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrecall_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1cadc03d5977>\u001b[0m in \u001b[0;36mrecall\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = [0,1,1,1,0,0,0,1]\n",
    "y_pred = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "recall_ = recall(y_true, y_pred)\n",
    "print('recall:', recall_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um bom modelo de machine learning, os valores de precision e recall precisam ser altos. Podemos observar isso no caso anterior, o valor de recall é 'um pouco' alto. Em contrapartida o valor de precision é muito baixo!\n",
    "\n",
    "Nosso modelo reproduz bastante falso positivos porém menos faso negativos. Poucos casos de falso negativos é bom nesse tipo de problema pois não queremos dizer que um paciente não possui pneumatórax quando na verdade ele possui. Isso pode proporcionar sérios problemas ! Porém ainda temos bastante falso positivos e isso também pode ser um problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grande parte dos modelos prevê probabilidade. Nessas predições nós geralmente escolhemos um threshold de 0,5. Esse limite (threshold) nao é sempre ideal e dependendo do valor escolhido para esse limite, os valores de precision e recall podem mudar drasticamente. Se para cada threshold que a gente escolher, calcularmos os valores de precision e recall, nos criamos uma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de Precision e Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos assumir que temos duas listas:\n",
    "* y_true: os valores de targets\n",
    "* y_pred: Valores de probabilidade da amostra em questão ser da classe 1\n",
    "\n",
    "Agora vamos olhar as probabilidades de predições ao invés do valor que foi predito ( o que é calculado na grande maioria das vezes considerando um limite de 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0,0,0,1,0,0,0,0,0,0,\n",
    "          1,0,0,0,0,0,0,0,1,0]\n",
    "\n",
    "\n",
    "y_pred = [.02638412, 0.11114267, 0.31620708, \n",
    "            0.0490937, 0.0191491, 0.17554844, \n",
    "            0.15952202, 0.03819563, 0.11639273, \n",
    "            0.079377, 0.08584789, 0.39095342, \n",
    "            0.27259048, 0.03447096, 0.04644807, \n",
    "            0.03543574, 0.18521942, 0.05934905, \n",
    "            0.61977213, 0.33056815]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(y_true))\n",
    "\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f4bc25d7cc90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtemp_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprecisions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fef6dfd5db63>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# limites ou thresholds\n",
    "thresholds = [0.0490937, 0.05934905, 0.079377,\n",
    "              0.08584789, 0.11114267, 0.11639273, \n",
    "              0.15952202, 0.17554844, 0.18521942, \n",
    "              0.27259048, 0.31620708, 0.33056815, \n",
    "              0.39095342, 0.61977213] \n",
    "\n",
    "# Para cada threshold, vamos calcular a predição em binário\n",
    "# e guardar os valores de precision e recall em duas listas distintas\n",
    "\n",
    "# Para cada valor dentro da lista y_pred, vamos verificar se esse valor é maior \n",
    "# ou igual a cada valor da lista de threshold. Se for, temp+prediction\n",
    "# adiciona 1 a lista, caso contrário adiciona 0\n",
    "for i in thresholds:\n",
    "    temp_prediction = [1 if x >= i else 0 for x in y_pred]\n",
    "\n",
    "    p = precision(y_true, temp_prediction)\n",
    "    r = recall( y_true, temp_prediction)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora plota os valores de precision e recall.\n",
    "\n",
    "### A curva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall', fontsize = 15)\n",
    "plt.ylabel('Precision', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cuva acima de precision e recall pode parecer diferente do que você está familiarizado a ver. Essa diferença ocorre devido ao fato de termos somente 20 dados com apensas 3 valores positivos. Porém não se preocupe, ela é a mesma curva de precision e recall que você está acostumado a ver pela internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A figura acima mostra que é difícil escolher um valor de threshold que nos de um bom valor de precision e recall.**\n",
    "\n",
    "Se o limite (threshold) é muito alto, teremos um pequeno número de dados **True Positive** e um **grande valor de falso negativo**. Isso diminui o valor de **Recall**, apensar disso o score de precision será mais alto.\n",
    "\n",
    "Por outro lado, se escolhermos um valor muito pequeno de threshold, o número de **false positives** irá crescer siginificativamente e a **precision** será menor.\n",
    "\n",
    "Esses valores de precision e recall variam entre 0 a 1 e quanto mais o score for próximo de 1, melhor !\n",
    "\n",
    "**F1 Score é a métrica que combina precision e recall.** É definida como uma média ponderada simples ou média harmônica da precision e do recall. Se considerarmos precision como P e recall como R, Podemos representar a **F1 Score** como:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score** \n",
    "    \n",
    "\\begin{equation*}\n",
    "F1 = \\frac{ 2PR }{(P+ R)}\\\\ \n",
    "\\end{equation*}\n",
    "\n",
    "Com um pouco de matemática chegamos a:\n",
    "\n",
    "\\begin{equation*}\n",
    "F1 = \\frac{ 2TP }{(2TP + FP + FN)}\\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em python temos:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    \n",
    "    f1_score = 2*p*r/ (p + r )\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-09916de0ff3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m          1,0,0,0,0,0,0,0,1,0]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-8302e23e8722>\u001b[0m in \u001b[0;36mf1\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fef6dfd5db63>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = [0,0,0,1,0,0,0,0,0,0,\n",
    "         1,0,0,0,0,0,0,0,1,0]\n",
    "\n",
    "\n",
    "y_pred = [0,0,1,0,0,0,1,0,0,0,\n",
    "         1,0,0,0,0,0,0,0,1,0]\n",
    "\n",
    "f1(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparando com scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao invés de olhar para precision e recall individualmente, nós podemos apenas olhar para o F1 score. Assim como precision, recall e accuracy, o F1 score varia de 0 a 1 e um modelo perfeito teria F1 igual a 1. **Quando lidamos com datasets com classes desbalanceadas, nós devemos olhar para F1 (ou recision e recall) ao invés de olhar a acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive Rate (TPR) e False Positive Rate (FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem outros termos importantes que precisamos saber que são **TPR ou True Positive Rate** e **FPR ou False Positive Rate**. Estes serão apresentados agora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive Rate (TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **TPR** \n",
    "    \n",
    "\\begin{equation*}\n",
    "TPR = \\frac{TP}{(TP+ FN)}\\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar da TPR ser a mesma coisa que Recall, vamos fazer uma função python para ela.\n",
    "\n",
    "* TPR ou Recall também é conhecido como **Sensitivity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(y_true, y_pred):\n",
    "    return recall(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Rate (FPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **FPR** \n",
    "    \n",
    "\\begin{equation*}\n",
    "FPR = \\frac{FP}{(TN + FP)}\\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr(y_true,y_pred):\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    return fp/(tn + fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Negative Rate ou Specificity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **True Negative Rate ou Specificity** \n",
    "    \n",
    "\\begin{equation*}\n",
    "FPR = 1- \\frac{FP}{(TN + FP)}\\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São realmente muitos termos porém **os mais importantes são apenas TNR e FPR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar que temos 15 dados e que os valores de targets são binários.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "y_true = [ 0,0,0,0,1,0,1,0,0,1,0,1,0,0,1 ]\n",
    "\n",
    "Vamos assumir que treinamos um modelo random forest, e temos a probabilidade de um determinado dado ser da classe positiva.\n",
    "\n",
    "prababilidade de ser 1 : [ 0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99 ] \n",
    "\n",
    "Para um valor de threshold  maior igual 0.5, nós podemos avaliar todos os valores de precision, recall/TPR, F1 score e FPR. Porém, Podemos fazer a mesma avaliação para diferentes valores de threshold. De fato, podemos escolher qualquer valor de 0 a 1 para calcular todas as métricas mensionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer essa avaliação levando em consideração somente duas métricas: TPR e FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_list = []\n",
    "fpr_list = []\n",
    "\n",
    "# Valor de target real\n",
    "y_true = [0,0,0,0,1,0,1,0,0,1,0,1,0,0,1]\n",
    "\n",
    "\n",
    "# Probabilidade do ser da classe positiva (1)\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99] \n",
    "\n",
    "# Threshold \n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0] \n",
    " \n",
    "for thresh in thresholds:\n",
    "    # Calcula a previsão para cada threshold\n",
    "    temp_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    "    # True Positive Rate\n",
    "    temp_tpr = tpr(y_true, temp_pred)\n",
    "    # False Positive Rate \n",
    "    temp_fpr = fpr(y_true, temp_pred) \n",
    "    # Inclui na lista \n",
    "    tpr_list.append(temp_tpr) \n",
    "    fpr_list.append(temp_fpr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "values = {\"threshold\":thresholds,\"tpr\":tpr_list,\"fpr\":fpr_list}\n",
    "tpr_fpr_df  = pd.DataFrame(values)\n",
    "tpr_fpr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usarmos os valores da tabela acima para fazer um plot com TPR no eixo Y e FPR no eixo X, teremos a seguinte curva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.fill_between(fpr_list, tpr_list, alpha = 0.4)\n",
    "plt.plot(fpr_list, tpr_list, lw = 3)\n",
    "plt.xlim(0, 1.0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel(\"FPR\", fontsize = 15)\n",
    "plt.ylabel(\"TPR\", fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa curva é conhecida como **Receiver Operating Characteristic (ROC)**. Se calcularmos a área dentro da curva, nós então estaremos calculando uma nova métrica que é muito usada quando temos um dataset com classes binárias desbalanceados.\n",
    "\n",
    "Essa métrica é conhecida como Area Under ROC curve ou Area Under the Curve ou AUC. Existem muitas maneiras de calcular essa área. Nós iremos usar o scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Os valores de AUC variam de 0  a 1.**\n",
    "* **AUC = 1** significa que temos um modelo perfeito. Na maioria das vezes, isso significa que tivemos algum erro com a validação e devemo analisar nosso preprocessamento e nossa pipeline de validaçao novamente.\n",
    "\n",
    "* **AUC = 0** significa que nosso modelo é muito ruim. Tente investigar as probabilidades para cada casse, por exemplo, se a probabilidade para uma classe positiva é p, tente substituir esse valor por 1-p. Esse tipo de AUC pode também signigicar que existem alguns problemas com o validation ou data processing.\n",
    "\n",
    "* **AUC = 0.5** significa que as predições estão sendo feitas de forma randomica ou aleatória.\n",
    "\n",
    "Se o valor de AUC cai dentro do intervalo [0 , 0.5], significa que o modelo está pior do que aleatório. Muitas vezes, esses valores são encontrados quando invertemos as classes dos nossos dados. Nesse caso, se a gente tentar inverter as predições, os valores de AUC provavelmente ficarão maiores que 0.5. **Quanto maior o valor da AUC, ou seja, quanto mais perto do 1, melhor!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos relembrar daquele nosso problema do pneumatórax. Imagine que ao criar um modeo que detecta pneumatórax em um paciente, o mesmo apresente um AUC de 0.80. O que isso significa? \n",
    "Um AUC de 0.80 significa que se a gente selecionar aleatoriamente uma imagem com pneumatórax - classe positiva - do nosso dataset e outra imagem aleatóia sem pneumatórax - classe negativa -, então a imagem com pneumatórax terá um rank maior do que a imagem sem pneumatórax com a probabilidade de 0.85.\n",
    "\n",
    "Depois que a gente calcular as probabilidades das classes e o AUC, nós iremos fazer as previsões com os dados de teste. Nós podemos usar tanto probabilidades quanto a classe para avaliar. A escolha da saída gerada vai depender do caso e do problema em questão. No caso de usar somente probabilidades, sem problemas pois a saida do modelo já pode nos dar isso sem problemas. Caso a gente queira ter a classe de saída, nós devemos especificar um **threshold**. Para o caso de classificação binária, podemos fazer o seguinte:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\\begin{equation*}\n",
    "classe-predita = Probabilidade >= Threshold \\\\ \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso nos dará uma lista que contém apenas valores binários - 1 se probabilidade maior igual ao threshold e 0 caso contrário.\n",
    "\n",
    "> **A pergunta que fica é: Como podemos calcular esse valor de threshold ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E como você já deve ter imaginado, nós podemos usar a curva ROC para avaliar como o valor de threshold impácta o FPT e o TPR e consequentemente os valores de FP(False Positive) e TP(True Positive). Tal análise depende tanto do tipo de negócio quanto do dataset, e , tendo isso em mente, devemos escolher o melhor valor de threshold que satisfaça as condicões de negócio e dos dados em questão.\n",
    "\n",
    "Por exemplo, se você não quer ter muitos false positives (FP), você deve escolher um threshold mais alto. Por outro lado, isso também fará com que tenha muito mais false netatives (FN). Fique atendo a esse trade-off e escolha com sabedoria.\n",
    "\n",
    "Agora vamos analisar como os valores de threshold impactam os valores de TP e FP.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_positive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a03fadca55fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtemp_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# tp e fp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtemp_tp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtemp_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_positive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_positive' is not defined"
     ]
    }
   ],
   "source": [
    "# listas vazias para guardar valores de TP e FP\n",
    "tp_list = []\n",
    "fp_list = []\n",
    "\n",
    "# Valores de target\n",
    "y_true = [0,0,0,0,1,0,1,0,0,1,0,1,0,0,1]\n",
    "\n",
    "\n",
    "# Probabilidades preditas da observação ser da classe 1\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99] \n",
    "\n",
    "# threshold escolhido a mão\n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
    "\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # Calcula previsão para um dado valor de threshold\n",
    "    temp_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    "    # tp e fp\n",
    "    temp_tp = true_positive(y_true, temp_pred)\n",
    "    temp_fp = false_positive(y_true, temp_pred)\n",
    "    \n",
    "    # add to list\n",
    "    tp_list.append(temp_tp)\n",
    "    fp_list.append(temp_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tpr_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c68b8409321b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtpr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fp\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfpr_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mthreshold_tp_fp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthreshold_tp_fp_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tpr_list' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = {'threshold':thresholds, \"tp\":tpr_list, \"fp\": fpr_list}\n",
    "\n",
    "threshold_tp_fp_df = pd.DataFrame(data) \n",
    "threshold_tp_fp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em muitos casos, o valor de ROC que fica na parte superior esquerda nos dá um threshold muito bom, como mostrado na figura abaixo. Como mostrado na imagem abaixo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.fill_between(fpr_list, tpr_list, alpha = 0.4)\n",
    "plt.plot(fpr_list, tpr_list, lw = 3)\n",
    "plt.xlim(0, 1.0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel(\"FPR\", fontsize = 15)\n",
    "plt.ylabel(\"TPR\", fontsize = 15)\n",
    "plt.annotate(' Possível melhor Threshold',\n",
    "            xy= ( 0.2, 0.8),\n",
    "            arrowprops=dict(arrowstyle='fancy', facecolor='red'\n",
    "                           ),\n",
    "            xytext = (0.6,0.5),\n",
    "            ha='center',\n",
    "            va='center')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a tabela e a Curva ROC, podemos notar que o threshold de cerca de 0.6 é um bom valor a ser escolhido. Nesse caso, nós não perdemos muitos true positives nem temos muitos casos de falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC é muito utilizado quando temos dados binários com classes desbalanceadas e é uma métrica que definitivamente todos deveriam saber. Uma vez que você entende o conceito por trás do AUC - apresentados anteriormente - se torna relativamente facil de explicar o conceito para pessoas não técnicas que irão utilizar o seu modelo na indústria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que entendemos sobre a AUC, podemos analisar a **log loss**. No caso de problema de classificação binária, a formlua é :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\\begin{equation*}\n",
    "Log Loss = -1.0*(target * log(prediction) + (1-target) * log(1-prediction))\\\\ \n",
    "\\end{equation*}\n",
    "\n",
    "Onde:\n",
    "* target é 1 ou 0\n",
    "* prediction é a prababilidade da amostra ser da classe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante notar que log loss penaliza bem por predição errada ou muito longe do valor real. Isso signigica que a **Log Loss nos pune por ter muita certeza e muito errado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_loss(y_true, y_proba):\n",
    "    epsilon = 1e-15\n",
    "    loss = []\n",
    "    \n",
    "    for yt, yp in zip(y_true, y_proba):\n",
    "        # ajuste de probabilidade\n",
    "        # 0 é convertido em 1e-15\n",
    "        # 1 é convertido em 1 - 1e-15\n",
    "        yp = np.clip(yp, epsilon, 1 - epsilon)\n",
    "        \n",
    "        temp_loss = - 1.0 * ( yt * np.log(yp) + (1 - yt) * np.log(1 - yp ))\n",
    "        loss.append(temp_loss)\n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 0, 0, 0, 1, 0, 1,0, 0, 1, 0, 1, 0, 0, 1]\n",
    "y_proba = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99]\n",
    "\n",
    "log_loss(y_true,y_proba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando scikit learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.log_loss(y_true,y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, nossa aplicação de log loss bate com o valor gerado com scikit learn. Um dos problemas do log loss é sua dificuldade de interpretar os resultados. Além disso, outro fato relevante é que nós precisamos lembrar que essa métrica gera mais penalidade que as outras métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, se você tem 51% de certeza com relação a uma amostra pertencer da classe positiva, a log loss será :\n",
    "\n",
    "  \n",
    "\\begin{equation*}\n",
    "Log Loss = -1.0*(1 * log(0.51) + (1-1) * log(1-0.51)) = 0.67\\\\ \n",
    "\\end{equation*}\n",
    "\n",
    "E se você tiver 49% de certeza de que uma amostra pertence a classe 0, a log loss será:\n",
    "\n",
    "\\begin{equation*}\n",
    "Log Loss = -1.0*(1 * log(0.49) + (1-0) * log(1-0.49)) = 0.67\\\\ \n",
    "\\end{equation*}\n",
    "\n",
    "Mesmo considerando um cut-off de 0.5 e tendo uma previsão perfeita, nós ainda teremos uma log loss muito alta. Então, quando estiver trabalhando com essa métrica, devemos ter bastante atenção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação multiclasse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitas das métricas mencionadas previamente podem ser convertidas para problemas com várias classes. Vamos analisar precision e recall. Para problemas multi classes, nós podemos calcular essas métricas para cada classe em questão. \n",
    "\n",
    "> ### Precision para Classificação multiclasse\n",
    "Existem diferentes maneiras de calcular essas métricas. Primeiramente, vamos tralhar com precision. Como sabemos, precision depende de True positive e false positive.\n",
    "\n",
    "* **Macro averaged precision: Calcula a precision para todas as classes individualmente e depois faz a média**\n",
    "\n",
    "* **Micro avaraged precision: Calcula true positives e false positives das classes e depois usa esse cálculo para calcular a precision total**\n",
    "\n",
    "* **Weighted precision: Similar a Macro precision considera média ponterada das classes, dependendo do número de itens em cada class.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos começar implementando em python o macro-average precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def macro_precision(y_true, y_pred):\n",
    "    \n",
    "    # Number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    precision = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        # Todas as classes exceto a atual é considerada negativa\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        \n",
    "        # precision para a classe em questao\n",
    "        temp_precision = tp/(tp +fp )\n",
    "        \n",
    "        precision += temp_precision\n",
    "        \n",
    "    # the ogeral precision\n",
    "    precision /= num_classes\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos agora implementar a micro-precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_precision(y_true, y_pred):\n",
    "    # número de classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # Inicializando tp e fp\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        # Calcula true positive para a classe em questão \n",
    "        # Faz update do tp total\n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "    \n",
    "        # Calcula false positive para a classe em questão\n",
    "        # Faz update do fp total\n",
    "        fp += false_positive(temp_true, temp_pred)\n",
    "\n",
    "    # Calcula a precision total\n",
    "    precision = tp / (tp + fp )\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos Calcular agora a weighted_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def weighted_precision(y_true, y_pred):\n",
    "    # número de classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    # criar um dicionario contando as classes\n",
    "    #{1 : 20, 2:15, 3:20}\n",
    "    class_counter = Counter(y_true)\n",
    "    \n",
    "    precision = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        \n",
    "        temp_precision = tp / (tp + fp)\n",
    "        \n",
    "        weighted_precision = class_counter[class_]*temp_precision\n",
    "        \n",
    "        precision += weighted_precision\n",
    "        \n",
    "    overall_precision = precision/ len(y_true)\n",
    "    return overall_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos comparar cada uma das métricas multiclass apresentadas com scikit-learn e verificar se o que fizemos está cert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nossa Função - macro precision: \", macro_precision(y_true, y_pred))\n",
    "print(\"scikit-learn - macro_precision \", metrics.precision_score(y_true, y_pred, average = \"macro\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nossa Função - micro precision: \", micro_precision(y_true, y_pred))\n",
    "print(\"scikit-learn - micro_precision \", metrics.precision_score(y_true, y_pred, average = \"micro\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nossa Função - weighted precision: \", weighted_precision(y_true, y_pred))\n",
    "print(\"scikit-learn - weighted_precision \", metrics.precision_score(y_true, y_pred, average = \"weighted\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que nossas funções estão certas. Todas apresentam resultados iguais aos encontrados quando usamos as métricas do scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como fizemos com a precisiom, nós poderíamos fazer o mesmo com **Recall** para nosso problema multiclass.Precision e Recall dependem de true positive, false positive e false negative. Já F1 score depende somente dos valores de precision e recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Recall para Classificação multiclasse\n",
    "Agora vamos trabalhar com recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def macro_recall(y_true, y_pred):\n",
    "    \n",
    "    # Number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    recall = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        # Todas as classes exceto a atual é considerada negativa\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fn = false_negative(temp_true, temp_pred)\n",
    "        \n",
    "        # recall para a classe em questao\n",
    "        temp_recall = tp/(tp +fn )\n",
    "        \n",
    "        recall += temp_recall\n",
    "        \n",
    "    #  recall geral\n",
    "    recall /= num_classes\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_recall(y_true, y_pred):\n",
    "    # número de classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # Inicializando tp e fn\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        # Calcula true positive para a classe em questão \n",
    "        # Faz update do tp total\n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "    \n",
    "        # Calcula false negative para a classe em questão\n",
    "        # Faz update do fp total\n",
    "        fn += false_negative(temp_true, temp_pred)\n",
    "\n",
    "    # Calcula a recall total\n",
    "    recall = tp / (tp + fn )\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def weighted_recall(y_true, y_pred):\n",
    "    # número de classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    # criar um dicionario contando as classes\n",
    "    #{1 : 20, 2:15, 3:20}\n",
    "    class_counter = Counter(y_true)\n",
    "    \n",
    "    recall = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fn = false_negative(temp_true, temp_pred)\n",
    "        \n",
    "        temp_recall = tp / (tp + fn)\n",
    "        \n",
    "        weighted_recall = class_counter[class_]*temp_recall\n",
    "        \n",
    "        recall += weighted_recall\n",
    "        \n",
    "    overall_recall = recall/ len(y_true)\n",
    "    return overall_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora fazer a comparação com as métricas do scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2] \n",
    "\n",
    "print(\"Nossa Função - macro recall: \", macro_recall(y_true, y_pred))\n",
    "print(\"scikit-learn - macro_recall \", metrics.recall_score(y_true, y_pred, average = \"macro\" ))\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Nossa Função - micro recall: \", micro_recall(y_true, y_pred))\n",
    "print(\"scikit-learn - micro_recall\", metrics.recall_score(y_true, y_pred, average = \"micro\" ))\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Nossa Função - weighted recall: \", weighted_recall(y_true, y_pred))\n",
    "print(\"scikit-learn - weighted_recall \", metrics.recall_score(y_true, y_pred, average = \"weighted\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### F1 para Classificação multiclasse\n",
    "Nós poderíamos fazer os mesmos cálculos para F1 score. A seguir Vamos calcular somente a F1 weighted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "def weighted_f1(y_true, y_pred):\n",
    "    # Número de classes\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    # dicionario com contador\n",
    "    class_counts = Counter(y_true)\n",
    "    \n",
    "    f1 = 0\n",
    "    \n",
    "    for class_ in range(n_classes):\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        p = precision(temp_true, temp_pred)\n",
    "        r = recall(temp_true, temp_pred)\n",
    "        \n",
    "        # calculando f1 da classe\n",
    "        if p + r != 0:\n",
    "            temp_f1 = 2 * p * r / (p + r)\n",
    "        else:\n",
    "            temp_f1 = 0\n",
    "            \n",
    "        # multiplica f1 pelo contador da classe\n",
    "        weighted_f1 = class_counts[class_] * temp_f1\n",
    "        \n",
    "        # Add no f1 score\n",
    "        f1 += weighted_f1\n",
    "        \n",
    "    # Calcula overall F1 - divide pelo total de amostras\n",
    "    overall_f1 = f1 / len(y_true)\n",
    "\n",
    "    return overall_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2] \n",
    "\n",
    "print(\"Nossa Função - weighted f1: \", weighted_f1(y_true, y_pred))\n",
    "print(\"scikit-learn -          f1: \", metrics.f1_score(y_true, y_pred, average = \"weighted\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apresentamos aqui precision, recall e F1 score para problemas multiclasses. Podemos ainda converter AUC e log loss para o formato multiclass também. A implementação é similar ao que vimos até então.\n",
    "\n",
    "Em problemas de classificação binários ou multiclass, é comum analisar a **confusion matrix**. Utilizando a confusion matrix, nós podemos, de forma simples, analisar o número de amostras classificadas corretamente ou não pelo nosso modelo. Se nós entendemos  TP, TN, FP e FN então entender confusion matrix se torna uma questão fácil. \n",
    "\n",
    "A imagem abaixo mostra o exemplo de uma confusion matrix para um problema de classificação binário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"confusion-matrix.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Onde:\n",
    "* Positivo verdadeiro (TP): classe positiva classificada corretamente\n",
    "* Falso positivo (FP): classe positiva classificada incorretamente\n",
    "* Falso negativo (FN): classe negativa classificada incorretamente\n",
    "* Verdadeiro negativo (TN): Classe negativa corretamente classificada\n",
    "\n",
    "Eu acho que olhando para a imagem abaixo você pode ter um melhor entendimento da matriz de confusão. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"errors.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Multiclass Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ainda expandir a confusion matrix para problemas de classificação multiclass. Sew tivermos N classes, teremos uma matriz de tamanho NxN.\n",
    "endit\n",
    "A confusion matrix abaixo nos mostra que :\n",
    "\n",
    "* Três instâncias da classe 0  que foram identificadas corretamente.\n",
    "* Uma amostra da classe 2 foi classifica como classe 0\n",
    "* Duas amostras da classe dois foram classificadas como classe 1\n",
    "* Uma amostra da classe 2 foi classificada como 2\n",
    "* Duas amostras da classe 1 foram classificadas como classe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(12.5, 0.5, 'Predicted labels')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "confusion_mat = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "cmap = sns.cubehelix_palette(50, hue = 0.05, rot = 0, light = 0.9, dark =0, as_cmap= True)\n",
    "sns.set(font_scale = 2.5)\n",
    "sns.heatmap(confusion_mat, annot = True, cmap = cmap, cbar = False)\n",
    "plt.xlabel(\"Actural Labels\", fontsize = 20)\n",
    "plt.ylabel(\"Predicted labels\", fontsize = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
